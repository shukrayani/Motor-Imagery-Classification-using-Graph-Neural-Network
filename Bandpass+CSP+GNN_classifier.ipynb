{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "from statistics import mean\n",
    "import statistics\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "import networkx as nx\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading continuous data of channels of subject aa\n",
    "channel = np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/aa/data_set_IVa_aa_cnt.txt\")\n",
    "#loading markers of subject aa\n",
    "markers= np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/aa/data_set_IVa_aa_mrk.txt\")\n",
    "#loading continuous data of channels of subject al\n",
    "channel1 = np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/al/data_set_IVa_al_cnt.txt\")\n",
    "#loading markers of subject aa\n",
    "markers1= np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/al/data_set_IVa_al_mrk.txt\")\n",
    "#loading continuous data of channels of subject av\n",
    "channel2 = np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/av/data_set_IVa_av_cnt.txt\")\n",
    "#loading markers of subject aa\n",
    "markers2= np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/av/data_set_IVa_av_mrk.txt\")\n",
    "#loading continuous data of channels of subject aw\n",
    "channel3 = np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/aw/data_set_IVa_aw_cnt.txt\")\n",
    "#loading markers of subject aa\n",
    "markers3= np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/aw/data_set_IVa_aw_mrk.txt\")\n",
    "#loading continuous data of channels of subject ay\n",
    "channel4 = np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/ay/data_set_IVa_ay_cnt.txt\")\n",
    "#loading markers of subject aa\n",
    "markers4 = np.loadtxt(fname = \"/home/shukra/Desktop/MTP/MI Data/Binary class_MI data/ay/data_set_IVa_ay_mrk.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 298458\n",
      "118 283574\n",
      "118 283042\n",
      "118 282838\n",
      "118 283562\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 100\n",
    "EEG = channel.T\n",
    "EEG1 = channel1.T\n",
    "EEG2 = channel2.T\n",
    "EEG3 = channel3.T\n",
    "EEG4 = channel4.T\n",
    "nchannels, nsamples = EEG.shape\n",
    "nchannels1, nsamples1 = EEG1.shape\n",
    "nchannels2, nsamples2 = EEG2.shape\n",
    "nchannels3, nsamples3 = EEG3.shape\n",
    "nchannels4, nsamples4 = EEG4.shape\n",
    "# channel names provided in nfo.txt file\n",
    "channel_names = ['Fp1', 'AFp1', 'Fpz', 'AFp2', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'FAF5', 'FAF1', 'FAF2', 'FAF6', \n",
    "                'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FFC7', 'FFC5', 'FFC3', 'FFC1', 'FFC2', 'FFC4', \n",
    "                'FFC6', 'FFC8', 'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'CFC7', \n",
    "                'CFC5', 'CFC3', 'CFC1', 'CFC2', 'CFC4', 'CFC6', 'CFC8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6'\n",
    "                , 'T8', 'CCP7', 'CCP5', 'CCP3', 'CCP1', 'CCP2', 'CCP4', 'CCP6', 'CCP8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1',\n",
    "                'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10', 'PCP7', 'PCP5', 'PCP3', 'PCP1', 'PCP2', 'PCP4', 'PCP6', 'PCP8', \n",
    "                'P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10', 'PPO7', 'PPO5', 'PPO1', 'PPO2', 'PPO6',\n",
    "                'PPO8', 'PO7', 'PO3', 'PO1', 'POz', 'PO2', 'PO4', 'PO8', 'OPO1', 'OPO2', 'O1', 'Oz', 'O2', 'OI1', 'OI2', \n",
    "                'I1', 'I2']\n",
    "# print the shape all cnt.txt file\n",
    "print(nchannels,nsamples)\n",
    "print(nchannels1,nsamples1)\n",
    "print(nchannels2,nsamples2)\n",
    "print(nchannels3,nsamples3)\n",
    "print(nchannels4,nsamples4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(markers.shape)\n",
    "# event_onsets contains markers of subject while event_code contain the label of that marker\n",
    "event_onsets = []\n",
    "event_codes = []\n",
    "event_onsets1 = []\n",
    "event_codes1 = []\n",
    "event_onsets2 = []\n",
    "event_codes2 = []\n",
    "event_onsets3 = []\n",
    "event_codes3 = []\n",
    "event_onsets4 = []\n",
    "event_codes4 = []\n",
    "# print(markers.T[1])\n",
    "# for loop is written to avoid the markers with label 0\n",
    "for i in markers:\n",
    "    if i[1]!=0:\n",
    "        event_onsets.append(int(i[0]))\n",
    "        event_codes.append(int(i[1]))\n",
    "for i in markers1:\n",
    "    if i[1]!=0:\n",
    "        event_onsets1.append(int(i[0]))\n",
    "        event_codes1.append(int(i[1]))\n",
    "for i in markers2:\n",
    "    if i[1]!=0:\n",
    "        event_onsets2.append(int(i[0]))\n",
    "        event_codes2.append(int(i[1]))\n",
    "for i in markers3:\n",
    "    if i[1]!=0:\n",
    "        event_onsets3.append(int(i[0]))\n",
    "        event_codes3.append(int(i[1]))\n",
    "for i in markers4:\n",
    "    if i[1]!=0:\n",
    "        event_onsets4.append(int(i[0]))\n",
    "        event_codes4.append(int(i[1]))\n",
    "event_onsets=[event_onsets]\n",
    "event_codes=[event_codes]\n",
    "event_onsets1=[event_onsets1]\n",
    "event_codes1=[event_codes1]\n",
    "event_onsets2=[event_onsets2]\n",
    "event_codes2=[event_codes2]\n",
    "event_onsets3=[event_onsets3]\n",
    "event_codes3=[event_codes3]\n",
    "event_onsets4=[event_onsets4]\n",
    "event_codes4=[event_codes4]\n",
    "# print(event_onsets)\n",
    "# print(event_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# label size is equal to total time samples in .cnt file\n",
    "labels = np.zeros((1, nsamples), int)\n",
    "print(labels)\n",
    "labels[0,event_onsets] = event_codes\n",
    "# here label shape would be [1,298458]\n",
    "\n",
    "labels1 = np.zeros((1, nsamples1), int)\n",
    "print(labels1)\n",
    "labels1[0,event_onsets1] = event_codes1\n",
    "\n",
    "\n",
    "labels2 = np.zeros((1, nsamples2), int)\n",
    "print(labels2)\n",
    "labels2[0,event_onsets2] = event_codes2\n",
    "\n",
    "\n",
    "labels3 = np.zeros((1, nsamples3), int)\n",
    "print(labels3)\n",
    "labels3[0,event_onsets3] = event_codes3\n",
    "\n",
    "labels4 = np.zeros((1, nsamples4), int)\n",
    "print(labels4)\n",
    "labels4[0,event_onsets4] = event_codes4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification\n",
    "cl_lab = ['right','foot'] \n",
    "cl1 = cl_lab[0]\n",
    "cl2 = cl_lab[1]\n",
    "nclasses = len(cl_lab)\n",
    "nevents = len(event_onsets)\n",
    "nevents1 = len(event_onsets1)\n",
    "nevents2 = len(event_onsets2)\n",
    "nevents3 = len(event_onsets3)\n",
    "nevents4 = len(event_onsets4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG: (118, 298458)\n",
      "Shape of EEG1: (118, 283574)\n",
      "Shape of EEG2: (118, 283042)\n",
      "Shape of EEG3: (118, 282838)\n",
      "Shape of EEG4: (118, 283562)\n",
      "Sample rate: 100\n",
      "Number of channels: 118\n",
      "Number of channels1: 118\n",
      "Number of channels2: 118\n",
      "Number of channels3: 118\n",
      "Number of channels4: 118\n",
      "Channel names: ['Fp1', 'AFp1', 'Fpz', 'AFp2', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'FAF5', 'FAF1', 'FAF2', 'FAF6', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FFC7', 'FFC5', 'FFC3', 'FFC1', 'FFC2', 'FFC4', 'FFC6', 'FFC8', 'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'CFC7', 'CFC5', 'CFC3', 'CFC1', 'CFC2', 'CFC4', 'CFC6', 'CFC8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'CCP7', 'CCP5', 'CCP3', 'CCP1', 'CCP2', 'CCP4', 'CCP6', 'CCP8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10', 'PCP7', 'PCP5', 'PCP3', 'PCP1', 'PCP2', 'PCP4', 'PCP6', 'PCP8', 'P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10', 'PPO7', 'PPO5', 'PPO1', 'PPO2', 'PPO6', 'PPO8', 'PO7', 'PO3', 'PO1', 'POz', 'PO2', 'PO4', 'PO8', 'OPO1', 'OPO2', 'O1', 'Oz', 'O2', 'OI1', 'OI2', 'I1', 'I2']\n",
      "Number of events: 1\n",
      "Number of events1: 1\n",
      "Number of events2: 1\n",
      "Number of events3: 1\n",
      "Number of events4: 1\n",
      "Event codes: [1 2]\n",
      "Class labels: ['right', 'foot']\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Print some information\n",
    "print('Shape of EEG:', EEG.shape)\n",
    "print('Shape of EEG1:', EEG1.shape)\n",
    "print('Shape of EEG2:', EEG2.shape)\n",
    "print('Shape of EEG3:', EEG3.shape)\n",
    "print('Shape of EEG4:', EEG4.shape)\n",
    "print('Sample rate:', sample_rate)\n",
    "print('Number of channels:', nchannels)\n",
    "print('Number of channels1:', nchannels1)\n",
    "print('Number of channels2:', nchannels2)\n",
    "print('Number of channels3:', nchannels3)\n",
    "print('Number of channels4:', nchannels4)\n",
    "print('Channel names:', channel_names)\n",
    "print('Number of events:', len(event_onsets))\n",
    "print('Number of events1:', len(event_onsets1))\n",
    "print('Number of events2:', len(event_onsets2))\n",
    "print('Number of events3:', len(event_onsets3))\n",
    "print('Number of events4:', len(event_onsets4))\n",
    "print('Event codes:', np.unique(event_codes))\n",
    "print('Class labels:', cl_lab)\n",
    "print('Number of classes:', nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the trials in, each class gets an entry\n",
    "trials = {}\n",
    "\n",
    "# The time window (in samples) to extract for each trial, here 0.5 -- 3.5 seconds first 0.5 data is skipped\n",
    "win = np.arange(int(0.5*sample_rate), int(3.5*sample_rate))\n",
    "# win1 = np.arange(int(1.0*sample_rate), int(1.5*sample_rate))\n",
    "# win2 = np.arange(int(1.5*sample_rate), int(2.0*sample_rate))\n",
    "# win3 = np.arange(int(2.0*sample_rate), int(2.5*sample_rate))\n",
    "# win4 = np.arange(int(2.5*sample_rate), int(3.0*sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(win))\n",
    "# print(len(win1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,)\n",
      "(118, 300, 112)\n",
      "(88,)\n",
      "(118, 300, 112)\n",
      "Shape of trials[cl1]: (118, 300, 112)\n",
      "Shape of trials[cl2]: (118, 300, 112)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Length of the time window\n",
    "nsamples = len(win)\n",
    "\n",
    "# Loop over the classes (right, foot)\n",
    "for cl, code in zip(cl_lab, np.unique(event_codes)):\n",
    "    event_codes = np.array(event_codes)\n",
    "    event_onsets = np.array(event_onsets)\n",
    "    event_codes1 = np.array(event_codes1)\n",
    "    event_onsets1 = np.array(event_onsets1)\n",
    "    event_codes2 = np.array(event_codes2)\n",
    "    event_onsets2 = np.array(event_onsets2)\n",
    "    event_codes3 = np.array(event_codes3)\n",
    "    event_onsets3 = np.array(event_onsets3)\n",
    "    event_codes4 = np.array(event_codes4)\n",
    "    event_onsets4 = np.array(event_onsets4)\n",
    "    # Extract the onsets for the class\n",
    "    cl_onsets = event_onsets[event_codes == code]\n",
    "    cl_onsets1 = event_onsets1[event_codes1 == code]\n",
    "    cl_onsets2 = event_onsets2[event_codes2 == code]\n",
    "    cl_onsets3 = event_onsets3[event_codes3 == code]\n",
    "    cl_onsets4 = event_onsets4[event_codes4 == code]\n",
    "    print(cl_onsets.shape)\n",
    "    # Allocate memory for the trials\n",
    "#     trials[cl] = np.zeros((nchannels, nsamples, len(cl_onsets)+len(cl_onsets2)+len(cl_onsets3)+len(cl_onsets4)))\n",
    "    trials[cl] = np.zeros((nchannels, nsamples, len(cl_onsets1)))\n",
    "    print(trials[cl].shape)\n",
    "    # Extract each trial\n",
    "    i=0\n",
    "    for onset in cl_onsets1:\n",
    "        trials[cl][:,:,i] = EEG[:, win+onset]\n",
    "        i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win1+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win2+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win3+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win4+onset]\n",
    "#         i+=1\n",
    "#     for onset in cl_onsets1:\n",
    "#         trials[cl][:,:,i] = EEG[:, win+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win1+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win2+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win3+onset]\n",
    "#         i+=1\n",
    "#         trials[cl][:,:,i] = EEG[:, win4+onset]\n",
    "#         i+=1\n",
    "#     for onset in cl_onsets2:\n",
    "#         trials[cl][:,:,i] = EEG[:, win+onset]\n",
    "#         i+=1\n",
    "#     for onset in cl_onsets3:\n",
    "#         trials[cl][:,:,i] = EEG[:, win+onset]\n",
    "#         i+=1\n",
    "#     for onset in cl_onsets4:\n",
    "#         trials[cl][:,:,i] = EEG[:, win+onset]\n",
    "#         i+=1\n",
    "  \n",
    "# Some information about the dimensionality of the data (channels x time x trials)\n",
    "# print(trials[cl1])\n",
    "# trials[cl1] will contain all the data with class label 'right'\n",
    "print('Shape of trials[cl1]:', trials[cl1].shape)\n",
    "# trials[cl2] will contain all the data with class label 'foot'\n",
    "print('Shape of trials[cl2]:', trials[cl2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import mlab\n",
    "\n",
    "def psd(trials):\n",
    "    '''\n",
    "    Calculates for each trial the Power Spectral Density (PSD).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials : 3d-array (channels x samples x trials)\n",
    "        The EEG signal\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    trial_PSD : 3d-array (channels x PSD x trials)\n",
    "        the PSD for each trial.  \n",
    "    freqs : list of floats\n",
    "        Yhe frequencies for which the PSD was computed (useful for plotting later)\n",
    "    '''\n",
    "    \n",
    "    ntrials = trials.shape[2]\n",
    "#     print(ntrials)\n",
    "    trials_PSD = np.zeros((nchannels, 151, ntrials))\n",
    "\n",
    "    # Iterate over trials and channels\n",
    "    for trial in range(ntrials):\n",
    "        for ch in range(nchannels):\n",
    "            # Calculate the PSD\n",
    "            (PSD, freqs) = mlab.psd(trials[ch,:,trial], NFFT=int(nsamples), Fs=sample_rate)\n",
    "            trials_PSD[ch, :, trial] = PSD.ravel()\n",
    "                \n",
    "    return trials_PSD, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "psd_r, freqs = psd(trials[cl1])\n",
    "psd_f, freqs = psd(trials[cl2])\n",
    "trials_PSD = {cl1: psd_r, cl2: psd_f}\n",
    "print(psd_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_psd(trials_PSD, freqs, chan_ind, chan_lab=None, maxy=None):\n",
    "    '''\n",
    "    Plots PSD data calculated with psd().\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials : 3d-array\n",
    "        The PSD data, as returned by psd()\n",
    "    freqs : list of floats\n",
    "        The frequencies for which the PSD is defined, as returned by psd() \n",
    "    chan_ind : list of integers\n",
    "        The indices of the channels to plot\n",
    "    chan_lab : list of strings\n",
    "        (optional) List of names for each channel\n",
    "    maxy : float\n",
    "        (optional) Limit the y-axis to this value\n",
    "    '''\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    nchans = len(chan_ind)\n",
    "    \n",
    "    # Maximum of 3 plots per row\n",
    "    nrows = np.ceil(nchans / 3)\n",
    "    ncols = min(3, nchans)\n",
    "    \n",
    "    # Enumerate over the channels\n",
    "    for i,ch in enumerate(chan_ind):\n",
    "        # Figure out which subplot to draw to\n",
    "        plt.subplot(nrows,ncols,i+1)\n",
    "    \n",
    "        # Plot the PSD for each class\n",
    "        for cl in trials.keys():\n",
    "            plt.plot(freqs, np.mean(trials_PSD[cl][ch,:,:], axis=1), label=cl)\n",
    "    \n",
    "        # All plot decoration below...\n",
    "        \n",
    "        plt.xlim(1,30)\n",
    "        \n",
    "        if maxy != None:\n",
    "            plt.ylim(0,maxy)\n",
    "    \n",
    "        plt.grid()\n",
    "    \n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        \n",
    "        if chan_lab == None:\n",
    "            plt.title('Channel %d' % (ch+1))\n",
    "        else:\n",
    "            plt.title(chan_lab[i])\n",
    "\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psd(\n",
    "    trials_PSD,\n",
    "    freqs,\n",
    "    [channel_names.index(ch) for ch in ['C3', 'Cz', 'C4']],\n",
    "    chan_lab=['left', 'center', 'right'],\n",
    "    maxy=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal \n",
    "\n",
    "def bandpass(trials, lo, hi, sample_rate):\n",
    "    '''\n",
    "    Designs and applies a bandpass filter to the signal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials : 3d-array (channels x samples x trials)\n",
    "        The EEGsignal\n",
    "    lo : float\n",
    "        Lower frequency bound (in Hz)\n",
    "    hi : float\n",
    "        Upper frequency bound (in Hz)\n",
    "    sample_rate : float\n",
    "        Sample rate of the signal (in Hz)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    trials_filt : 3d-array (channels x samples x trials)\n",
    "        The bandpassed signal\n",
    "    '''\n",
    "\n",
    "    # The iirfilter() function takes the filter order: higher numbers mean a sharper frequency cutoff,\n",
    "    # but the resulting signal might be shifted in time, lower numbers mean a soft frequency cutoff,\n",
    "    # but the resulting signal less distorted in time. It also takes the lower and upper frequency bounds\n",
    "    # to pass, divided by the niquist frequency, which is the sample rate divided by 2:\n",
    "    a, b = scipy.signal.iirfilter(6, [lo/(sample_rate/2.0), hi/(sample_rate/2.0)])\n",
    "\n",
    "    # Applying the filter to each trial\n",
    "    ntrials = trials.shape[2]\n",
    "    trials_filt = np.zeros((nchannels, nsamples, ntrials))\n",
    "    for i in range(ntrials):\n",
    "        trials_filt[:,:,i] = scipy.signal.filtfilt(a, b, trials[:,:,i], axis=1)\n",
    "    \n",
    "    return trials_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "trials_filt = {cl1: bandpass(trials[cl1], 8, 15, sample_rate),\n",
    "               cl2: bandpass(trials[cl2], 8, 15, sample_rate)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_r, freqs = psd(trials_filt[cl1])\n",
    "psd_f, freqs = psd(trials_filt[cl2])\n",
    "trials_PSD = {cl1: psd_r, cl2: psd_f}\n",
    "\n",
    "plot_psd(\n",
    "    trials_PSD,\n",
    "    freqs,\n",
    "    [channel_names.index(ch) for ch in ['C3', 'Cz', 'C4']],\n",
    "    chan_lab=['left', 'center', 'right'],\n",
    "    maxy=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log(var) of the trials\n",
    "def logvar(trials):\n",
    "    '''\n",
    "    Calculate the log-var of each channel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials : 3d-array (channels x samples x trials)\n",
    "        The EEG signal.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    logvar - 2d-array (channels x trials)\n",
    "        For each channel the logvar of the signal\n",
    "    '''\n",
    "#     print(np.log(np.var(trials[0], axis=1)).shape)\n",
    "    return np.log(np.var(trials, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "trials_logvar = {cl1: logvar(trials_filt[cl1]),\n",
    "                 cl2: logvar(trials_filt[cl2])}\n",
    "print(trials_logvar['right'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logvar(trials):\n",
    "    '''\n",
    "    Plots the log-var of each channel/component.\n",
    "    arguments:\n",
    "        trials - Dictionary containing the trials (log-vars x trials) for 2 classes.\n",
    "    '''\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    x0 = np.arange(nchannels)\n",
    "    x1 = np.arange(nchannels) + 0.4\n",
    "\n",
    "    y0 = np.mean(trials[cl1], axis=1)\n",
    "    y1 = np.mean(trials[cl2], axis=1)\n",
    "\n",
    "    plt.bar(x0, y0, width=0.5, color='b')\n",
    "    plt.bar(x1, y1, width=0.4, color='r')\n",
    "\n",
    "    plt.xlim(-0.5, nchannels+0.5)\n",
    "\n",
    "    plt.gca().yaxis.grid(True)\n",
    "    plt.title('log-var of each channel/component')\n",
    "    plt.xlabel('channels/components')\n",
    "    plt.ylabel('log-var')\n",
    "    plt.legend(cl_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log-vars\n",
    "plot_logvar(trials_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def cov(trials):\n",
    "    ''' Calculate the covariance for each trial and return their average '''\n",
    "    ntrials = trials.shape[2]\n",
    "    covs = [ trials[:,:,i].dot(trials[:,:,i].T) / nsamples for i in range(ntrials) ]\n",
    "    return np.mean(covs, axis=0)\n",
    "\n",
    "def whitening(sigma):\n",
    "    ''' Calculate a whitening matrix for covariance matrix sigma. '''\n",
    "    U, l, _ = linalg.svd(sigma)\n",
    "    return U.dot( np.diag(l ** -0.5) )\n",
    "\n",
    "def csp(trials_r, trials_f):\n",
    "    '''\n",
    "    Calculate the CSP transformation matrix W.\n",
    "    arguments:\n",
    "        trials_r - Array (channels x samples x trials) containing right hand movement trials\n",
    "        trials_f - Array (channels x samples x trials) containing foot movement trials\n",
    "    returns:\n",
    "        Mixing matrix W\n",
    "    '''\n",
    "    cov_r = cov(trials_r)\n",
    "#     print(cov_r)\n",
    "    cov_f = cov(trials_f)\n",
    "    P = whitening(cov_r + cov_f)\n",
    "    B, _, _ = linalg.svd( P.T.dot(cov_f).dot(P) )\n",
    "    W = P.dot(B)\n",
    "    return W\n",
    "\n",
    "def apply_mix(W, trials):\n",
    "    ''' Apply a mixing matrix to each trial (basically multiply W with the EEG signal matrix)'''\n",
    "    ntrials = trials.shape[2]\n",
    "    trials_csp = np.zeros((nchannels, nsamples, ntrials))\n",
    "    for i in range(ntrials):\n",
    "        trials_csp[:,:,i] = W.T.dot(trials[:,:,i])\n",
    "    return trials_csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the functions\n",
    "W = csp(trials_filt[cl1], trials_filt[cl2])\n",
    "trials_csp = {cl1: apply_mix(W, trials_filt[cl1]),\n",
    "              cl2: apply_mix(W, trials_filt[cl2])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials1 = trials_csp[cl1].shape[2]\n",
    "ntrials2 = trials_csp[cl2].shape[2]\n",
    "output_bp_csp = np.zeros((30, nsamples, ntrials1+ntrials2))\n",
    "print(output_bp_csp.shape)\n",
    "channels_selected = ['FC2', 'FC4', 'FC6', 'CFC2', 'CFC4','CFC6', 'C2', 'C4', 'C6', 'CCP2', 'CCP4', 'CCP6', 'CP2', 'CP4', 'CP6', 'FC5', 'FC3', 'FC1', 'CFC5', 'CFC3', 'CFC1', 'C5',\n",
    "'C3', 'C1', 'CCP5', 'CCP3', 'CCP1', 'CP5', 'CP3', 'CP1']\n",
    "\n",
    "# for creating one file per person per trial\n",
    "y_list=[]\n",
    "j=0\n",
    "for i in range(trials_csp[cl1].shape[2]):\n",
    "    single = trials_csp[cl1][:,:,i].T\n",
    "    df = pd.DataFrame(data=single,columns=channel_names)\n",
    "    df=df[channels_selected].T\n",
    "    a = np.array(df)\n",
    "    output_bp_csp[:,:,j]=a\n",
    "    j+=1\n",
    "    y_list.append(0)\n",
    "for i in range(trials_csp[cl2].shape[2]):\n",
    "    single = trials_csp[cl2][:,:,i].T\n",
    "    df = pd.DataFrame(data=single,columns=channel_names)\n",
    "    df=df[channels_selected].T\n",
    "    a = np.array(df)\n",
    "    output_bp_csp[:,:,j]=a\n",
    "    j+=1\n",
    "    y_list.append(1)\n",
    " \n",
    "print(output_bp_csp.shape)\n",
    "f = open(\"Bandpass+CSP_ay\", \"wb\")\n",
    "pickle.dump(output_bp_csp, f)\n",
    "f.close()\n",
    "f = open(\"Bandpass+CSP_ay_label\", \"wb\")\n",
    "pickle.dump(y_list, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_logvar = {cl1: logvar(trials_csp[cl1]),\n",
    "                 cl2: logvar(trials_csp[cl2])}\n",
    "plot_logvar(trials_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_r, freqs = psd(trials_csp[cl1])\n",
    "psd_f, freqs = psd(trials_csp[cl2])\n",
    "trials_PSD = {cl1: psd_r, cl2: psd_f}\n",
    "\n",
    "plot_psd(trials_PSD, freqs, [20,58,-20], chan_lab=['first component', 'middle component', 'last component'], maxy=0.75 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(left, foot):\n",
    "    plt.figure()\n",
    "    plt.scatter(left[15,:], left[-15,:], color='b')\n",
    "    plt.scatter(foot[15,:], foot[-15,:], color='r')\n",
    "    plt.xlabel('Last component')\n",
    "    plt.ylabel('First component')\n",
    "    plt.legend(cl_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(trials_logvar[cl1], trials_logvar[cl2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of trials to use for training (50-50 split here)\n",
    "train_percentage = 0.8\n",
    "\n",
    "# Calculate the number of trials for each class the above percentage boils down to\n",
    "ntrain_r = int(trials_filt[cl1].shape[2] * train_percentage)\n",
    "ntrain_f = int(trials_filt[cl2].shape[2] * train_percentage)\n",
    "ntest_r = trials_filt[cl1].shape[2] - ntrain_r\n",
    "ntest_f = trials_filt[cl2].shape[2] - ntrain_f\n",
    "\n",
    "# Splitting the frequency filtered signal into a train and test set\n",
    "train = {cl1: trials_filt[cl1][:,:,:ntrain_r],\n",
    "         cl2: trials_filt[cl2][:,:,:ntrain_f]}\n",
    "\n",
    "test = {cl1: trials_filt[cl1][:,:,ntrain_r:],\n",
    "        cl2: trials_filt[cl2][:,:,ntrain_f:]}\n",
    "\n",
    "# Train the CSP on the training set only\n",
    "W = csp(train[cl1], train[cl2])\n",
    "\n",
    "# Apply the CSP on both the training and test set\n",
    "train[cl1] = apply_mix(W, train[cl1])\n",
    "train[cl2] = apply_mix(W, train[cl2])\n",
    "test[cl1] = apply_mix(W, test[cl1])\n",
    "test[cl2] = apply_mix(W, test[cl2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[cl1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels_selected = ['FC2', 'FC4', 'FC6', 'CFC2', 'CFC4','CFC6', 'C2', 'C4', 'C6', 'CCP2', 'CCP4', 'CCP6', 'CP2', 'CP4', 'CP6', 'FC5', 'FC3', 'FC1', 'CFC5', 'CFC3', 'CFC1', 'C5',\n",
    "# 'C3', 'C1', 'CCP5', 'CCP3', 'CCP1', 'CP5', 'CP3', 'CP1']\n",
    "channels_selected = ['C3', 'Cz', 'C4']\n",
    "ntrials = trials_csp[cl1].shape[2]\n",
    "input_list=[]\n",
    "tmp=0\n",
    "for i in range(ntrials):\n",
    "    data = trials_csp[cl1][:,:,i].T\n",
    "    df = pd.DataFrame(data=data,columns=channel_names)\n",
    "    pearsonCorrelation={}\n",
    "    #adJMatrix=[]\n",
    "    for i in channels_selected:\n",
    "        #matrix_list=[]\n",
    "        for j in channels_selected:\n",
    "            x=df[i]\n",
    "            x_t=np.array(x).T\n",
    "            y=df[j]\n",
    "            y_t=np.array(y).T\n",
    "            r=np.corrcoef(x_t,y_t)\n",
    "            pearsonCorrelation[(i,j)]=r[0,1]\n",
    "    partialCorrelation=dict()\n",
    "    # adJMatrix is to store the Ajencency matrix\n",
    "    adJMatrix=[]\n",
    "    features_total=[]\n",
    "    for i in channels_selected:\n",
    "        matrix_list=[]\n",
    "        features=[]\n",
    "        features.append(mean(df[i]))\n",
    "        features.append(statistics.median(df[i]))\n",
    "        features.append(np.std(np.array(df[i]).T, dtype = np.float64))\n",
    "        features.append(skew(df[i]))\n",
    "        features_total.append(features)\n",
    "        for j in channels_selected:\n",
    "            list=[]\n",
    "            i_j=pearsonCorrelation[(i,j)]\n",
    "            for k in channels_selected:\n",
    "                if k is not i and k is not j:\n",
    "                    j_k=pearsonCorrelation[(j,k)]\n",
    "                    i_k=pearsonCorrelation[(i,k)]\n",
    "                    partial_corr=((i_j-(j_k*i_k))/math.sqrt((1-i_k*i_k)*(1-j_k*j_k)))\n",
    "                    list.append(partial_corr)\n",
    "            if min(list)>0.3:\n",
    "                partialCorrelation[(i,j)]=min(list)\n",
    "                matrix_list.append(1)\n",
    "            else:\n",
    "                partialCorrelation[(i,j)]=0\n",
    "                matrix_list.append(0)\n",
    "        adJMatrix.append(matrix_list)\n",
    "    input_list.append([adJMatrix, 0,features_total])\n",
    "#     print(tmp)\n",
    "    tmp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = trials_csp[cl2].shape[2]\n",
    "for i in range(ntrials):\n",
    "    data = trials_csp[cl2][:,:,i].T\n",
    "    df = pd.DataFrame(data=data,columns=channel_names)\n",
    "    pearsonCorrelation={}\n",
    "    #adJMatrix=[]\n",
    "    for i in channels_selected:\n",
    "        #matrix_list=[]\n",
    "        for j in channels_selected:\n",
    "            x=df[i]\n",
    "            x_t=np.array(x).T\n",
    "            y=df[j]\n",
    "            y_t=np.array(y).T\n",
    "            r=np.corrcoef(x_t,y_t)\n",
    "            pearsonCorrelation[(i,j)]=r[0,1]\n",
    "    partialCorrelation=dict()\n",
    "    # adJMatrix is to store the Ajencency matrix\n",
    "    adJMatrix=[]\n",
    "    features_total=[]\n",
    "    for i in channels_selected:\n",
    "        matrix_list=[]\n",
    "        features=[]\n",
    "        features.append(mean(df[i]))\n",
    "        features.append(statistics.median(df[i]))\n",
    "        features.append(np.std(np.array(df[i]).T, dtype = np.float64))\n",
    "        features.append(skew(df[i]))\n",
    "        features_total.append(features)\n",
    "        for j in channels_selected:\n",
    "            list=[]\n",
    "            i_j=pearsonCorrelation[(i,j)]\n",
    "            for k in channels_selected:\n",
    "                if k is not i and k is not j:\n",
    "                    j_k=pearsonCorrelation[(j,k)]\n",
    "                    i_k=pearsonCorrelation[(i,k)]\n",
    "                    partial_corr=((i_j-(j_k*i_k))/math.sqrt((1-i_k*i_k)*(1-j_k*j_k)))\n",
    "                    list.append(partial_corr)\n",
    "            if min(list)>0.3:\n",
    "                partialCorrelation[(i,j)]=min(list)\n",
    "                matrix_list.append(1)\n",
    "            else:\n",
    "                partialCorrelation[(i,j)]=0\n",
    "                matrix_list.append(0)\n",
    "        adJMatrix.append(matrix_list)\n",
    "    input_list.append([adJMatrix, 1,features_total])\n",
    "#     print(tmp)\n",
    "    tmp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Bandpass+CSP+GNN_al\", \"wb\")\n",
    "random.shuffle(input_list)\n",
    "pickle.dump(input_list, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(input_list[0][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
